"""Run the filtering pipeline"""
import argparse
import importlib
import os
import json
import sys

from filter.config_filter import config_filter
from merge.preprocessing import load_json, get_merges, get_mol, get_protein


class FilterPipeline():

    def __init__(self, merge: str, smis: list, synthons: list, fragmentA: str, fragmentB: str, proteinA: str,
                 proteinB: str, filter_steps: list, score_steps: list):
        self.merge = merge
        self.smis = smis
        self.synthons = synthons
        self.fragmentA = fragmentA  # filepath
        self.fragmentB = fragmentB  # filepath
        self.proteinA = proteinA  # filepath
        self.proteinB = proteinB  # filepath
        self.filter_steps = filter_steps  # record the filter steps to use in the pipeline
        self.score_steps = score_steps  # record the scoring metrics to score the filtered merges
        self.mols = None
        self.results = None  # record the results for each filter (True for pass; False for fail)
        self.failures = {}  # record the SMILES that failed and at which filter
        self.score_dict = {}

        # get unique merge name - will be used for naming output files
        self.names = [self.merge + '_' + str(i) for i, _ in enumerate(self.smis)]

        # store filepaths generated by the filtering pipeline
        self.mol_files = None
        self.holo_files = None
        self.apo_files = None

    def _remove_failed(self, filter_name: str):
        """
        Remove the failed molecules from the list of SMILES/synthons/mols to pass into the next filter.
        Record the failed SMILES and at which filter they failed in a dictionary.

        :param filter_name: name of the filter just run
        :type filter_name: str
        """
        for i, res in reversed(list(enumerate(self.results))):
            if not res:  # if merge failed the filter, then remove from data
                smi = self.smis[i]
                synthon = self.synthons[i]
                name = self.names[i]

                # record the failed smile in self.failures dict
                inner_dict = {'smiles': smi, 'synthon': synthon, 'failed_filter': filter_name}
                self.failures[name] = inner_dict

                self.smis.pop(i)
                self.synthons.pop(i)
                self.names.pop(i)
                if self.mols:  # if mols have been generated, remove failed merge
                    self.mols.pop(i)
                if self.mol_files:
                    self.mol_files.pop(i)
                if self.apo_files:
                    self.apo_files.pop(i)
                if self.holo_files:
                    self.holo_files.pop(i)

    def execute_pipeline(self):
        """
        For each step in the pipeline, the function retrieves the module/class and runs the filter. Each filter
        returns a list of results (True or False) and a list of molecules (returns if None if the filter does not
        generate any conformations) - the list of molecules is then passed into the next filter. Prints how many
        molecules were removed by each filter.
        """
        for step in self.filter_steps:  # step specifies the class name for the filter
            n_smi = len(self.smis)
            module = config_filter.PIPELINE_DICT[step]  # retrieve module name
            cls = getattr(importlib.import_module(module), step)  # retrieve the class
            filter = cls(self.smis, self.synthons, self.fragmentA, self.fragmentB, self.proteinA, self.proteinB,
                         self.merge, self.mols, self.names)  # initialise the filter
            self.results, self.mols = filter.filter_all()  # run the filter
            # if the filter creates placed mol/pdb files, retrieve them (will stay as None if not)
            self.mol_files, self.holo_files, self.apo_files = filter.get_placed_files()
            self._remove_failed(step)  # remove failed mols from the smiles/synthon/mol lists

            n_removed = n_smi - len(self.smis)
            print(f'{n_removed} mols removed by {step}. {len(self.smis)} mols remaining.')

        if len(self.smis) > 0 and len(self.score_steps) > 0 and self.mol_files or self.holo_files or self.apo_files:

            for step in self.score_steps:
                module = config_filter.PIPELINE_DICT[step]  # retrieve module name
                cls = getattr(importlib.import_module(module), step)  # retrieve the class
                score = cls(self.smis, self.synthons, self.fragmentA, self.fragmentB, self.proteinA, self.proteinB,
                            self.merge, self.mols, self.names, self.mol_files, self.holo_files, self.apo_files)
                self.score_dict[step] = score.score_all()
                print(f'Scoring metric {step} run on filtered merges.')

    def return_results(self):
        """
        Return the results after filtering.

        :return: list of filtered SMILES; dictionary with SMILES as key and failed filter as the value
        :rtype: Tuple[list, dict]
        """
        if len(self.score_dict) > 0:
            results_dict = {}
            for i, (name, smi, synthon) in enumerate(zip(self.names, self.smis, self.synthons)):
                inner_dict = {'smiles': smi, 'synthon': synthon}
                for score in self.score_dict:
                    inner_dict[score] = self.score_dict[score][i]
                results_dict[name] = inner_dict

        else:
            results_dict = {}
            for i, (name, smi, synthon) in enumerate(zip(self.names, self.smis, self.synthons)):
                inner_dict = {'smiles': smi, 'synthon': synthon}
                results_dict[name] = inner_dict

        return results_dict, self.failures


def parse_args(args):
    # get file containing merges and all fragment/protein files
    parser = argparse.ArgumentParser(epilog='''
    Example
    python -m filter.filter_pipeline -f x0034_0B_x0176_0B.json -m x0034_0B_x0176_0B -t nsp13 -o data/example_folder''')
    parser.add_argument('-f', '--merge_file', help='the json file containing the merges')
    parser.add_argument('-m', '--merge', help='the name of the merge, e.g. x0107_0A_x0434_0A')
    parser.add_argument('-t', '--target', help='the name of the target, e.g. nsp13 or Mpro')
    parser.add_argument('-o', '--output_dir', help='the directory to write the filtered files to')
    return parser.parse_args(args)


def main():
    args = parse_args(sys.argv[1:])
    merge = args.merge

    # open json file containing merges
    merges_dict = load_json(args.merge_file)
    synthons, smiles = get_merges(merges_dict)
    print("Number of smiles: %d" % len(smiles))

    # load fragments and proteins
    fragments = args.merge.split('-')
    fA = fragments[0]
    fB = fragments[1]
    fragmentA = get_mol(args.target, fA, config_filter.FRAGALYSIS_DATA_DIR)
    fragmentB = get_mol(args.target, fB, config_filter.FRAGALYSIS_DATA_DIR)
    proteinA = get_protein(args.target, fA, config_filter.FRAGALYSIS_DATA_DIR)
    proteinB = get_protein(args.target, fB, config_filter.FRAGALYSIS_DATA_DIR)
    filter_steps = config_filter.FILTER_PIPELINE
    score_steps = config_filter.SCORING_PIPELINE

    # execute the pipeline
    pipeline = FilterPipeline(merge, smiles, synthons, fragmentA, fragmentB, proteinA, proteinB, filter_steps,
                              score_steps)
    print(pipeline.names)
    pipeline.execute_pipeline()
    print(f'{len(pipeline.smis)} mols after filtering.')
    results, failures = pipeline.return_results()

    # save in json files
    filtered_fname = merge + '_filtered.json'
    filtered_fpath = os.path.join(args.output_dir, filtered_fname)

    failed_fname = merge + '_failures.json'
    failed_fpath = os.path.join(args.output_dir, failed_fname)

    with open(filtered_fpath, 'w') as f:
        json.dump(results, f)

    with open(failed_fpath, 'w') as f:
        json.dump(failures, f)


if __name__ == "__main__":
    main()

# config = 'tests.test_config'
# cls = getattr(importlib.import_module(config), 'TestConfig')  # retrieve the class
# print(cls.CONFIG_DICT['FRAGALYSIS_DATA_DIR'])
